{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107261\n",
      "                         0              1\n",
      "11206           Dorogobuzh         ドロゴブージ\n",
      "80376         Gail Hopkins      ゲイル・ホプキンス\n",
      "38108              Novatek          ノヴァテク\n",
      "29960      Gyula Cseszneky     チェスネキー・ジュラ\n",
      "22295  Occhieppo Superiore  オッキエッポ・スペリオーレ\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/joined_titles.csv', header=None)\n",
    "data = data.sample(frac=1, random_state=0)\n",
    "\n",
    "print(len(data))\n",
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dorogobuzh', 'gail hopkins', 'novatek']\n",
      "['ドロゴブージ', 'ゲイル・ホプキンス', 'ノヴァテク']\n"
     ]
    }
   ],
   "source": [
    "data_input = [s.lower() for s in data[0]]\n",
    "data_output = [s.lower() for s in data[1]]\n",
    "\n",
    "print(data_input[0:3])\n",
    "print(data_output[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64356\n",
      "10726\n"
     ]
    }
   ],
   "source": [
    "data_size = len(data)\n",
    "\n",
    "training_split_index = int(data_size*60/100)\n",
    "validation_split_index = int(data_size*70/100)\n",
    "\n",
    "# We will use the first 0-60th %-tile (60%) of data for the training\n",
    "training_input  = data_input[:training_split_index]\n",
    "training_output = data_output[:training_split_index]\n",
    "\n",
    "# We will use the first 60-70th %-tile (10%) of data for the training\n",
    "validation_input = data_input[training_split_index:validation_split_index]\n",
    "validation_output = data_output[training_split_index:validation_split_index]\n",
    "\n",
    "print(len(training_input))\n",
    "print(len(validation_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding character input\n",
    "\n",
    "We will create a character dictionary and encode the title from a string (a sequence of character) into a sequence of IDs. We will also create the reverse dictionary that will be used for getting the result later.\n",
    "\n",
    "Note that in practice, we must not build the dictionary from all data (`data_input` and `data_output`), but only use the training set (`training_input` and `training_output`). We also have to handle out-of-dictionary characters. However, for now, I will skip that part.\n",
    "\n",
    "Note:\n",
    "- We will use 0 for padding and 1 for 'START'. So, `count` starts from 2. \n",
    "- This is to take advantage of `mask_zero=True` feature for Embedding Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English character dict size: 54\n",
      "Katakana character dict size: 89\n",
      "[('p', 2), ('r', 3), ('õ', 4), ('h', 5), ('ò', 6)]\n",
      "[('ヅ', 2), ('ビ', 3), ('プ', 4), ('コ', 5), ('ト', 6)]\n"
     ]
    }
   ],
   "source": [
    "START_CHAR_CODE = 1\n",
    "\n",
    "def encode_characters(titles):\n",
    "    count = 2\n",
    "    encoding = {}\n",
    "    decoding = {1: 'START'}\n",
    "    for c in set([c for title in titles for c in title]):\n",
    "        encoding[c] = count\n",
    "        decoding[count] = c\n",
    "        count += 1\n",
    "    return encoding, decoding, count\n",
    "\n",
    "\n",
    "input_encoding, input_decoding, input_dict_size = encode_characters(data_input)\n",
    "output_encoding, output_decoding, output_dict_size = encode_characters(data_output)\n",
    "\n",
    "\n",
    "print('English character dict size:', input_dict_size)\n",
    "print('Katakana character dict size:', output_dict_size)\n",
    "\n",
    "print(list(input_encoding.items())[0:5])\n",
    "print(list(output_encoding.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Transforming the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input [[50 17  3 ...  0  0  0]\n",
      " [42 16 25 ...  0  0  0]\n",
      " [53 17 26 ...  0  0  0]\n",
      " ...\n",
      " [30 16 49 ...  0  0  0]\n",
      " [50 35  5 ...  0  0  0]\n",
      " [21 25 28 ...  0  0  0]]\n",
      "output [[53  9  8 ...  0  0  0]\n",
      " [32 35 55 ...  0  0  0]\n",
      " [29 15 31 ...  0  0  0]\n",
      " ...\n",
      " [61 35  6 ...  0  0  0]\n",
      " [68 82 19 ...  0  0  0]\n",
      " [76 60 65 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "def transform(encoding, data, vector_size):\n",
    "    transformed_data = np.zeros(shape=(len(data), vector_size), dtype='int')\n",
    "    for i in range(len(data)):\n",
    "        for j in range(min(len(data[i]), vector_size)):\n",
    "            transformed_data[i][j] = encoding[data[i][j]]\n",
    "    return transformed_data\n",
    "\n",
    "INPUT_LENGTH = 20\n",
    "OUTPUT_LENGTH = 20\n",
    "\n",
    "encoded_training_input = transform(input_encoding, training_input, vector_size=INPUT_LENGTH)\n",
    "encoded_training_output = transform(output_encoding, training_output, vector_size=OUTPUT_LENGTH)\n",
    "encoded_validation_input = transform(input_encoding, validation_input, vector_size=INPUT_LENGTH)\n",
    "encoded_validation_output = transform(output_encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
    "\n",
    "print('input', encoded_training_input)\n",
    "print('output', encoded_training_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
    "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "First, we will use [Embedding layer](https://keras.io/layers/embeddings/) to transform input char-id sequence into dense vectors.  \n",
    "\n",
    "The input vectors will be passed to a [Recurrent layer](https://keras.io/layers/recurrent/) (we use LSTM) that will transform the vectors of each input character to a single output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 64)\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder = Embedding(input_dict_size, 64, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
    "encoder = LSTM(64)(encoder)\n",
    "\n",
    "print(encoder.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Our decoder generate Katakana sequence (as a softmax prediction) on characrter at the time. Every generated output at decoding step will be passed back as an input of the decoder to generate the next output.\n",
    "\n",
    "Similar to the encoder, the input will be passed to an Embedding layer to transform the input into dense vectors and pass them to LSTM.\n",
    "\n",
    "We will use the encoder's output to initialize decoder state (`initial_state`).\n",
    "\n",
    "The final layer will be (time distributed) Dense layer that will produce the softmax prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20, 89)\n"
     ]
    }
   ],
   "source": [
    "decoder = Embedding(output_dict_size, 64, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
    "\n",
    "decoder = LSTM(64, return_sequences=True)(decoder, initial_state=[encoder, encoder])\n",
    "decoder = TimeDistributed(Dense(output_dict_size, activation=\"softmax\"))(decoder)\n",
    "\n",
    "print(decoder.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input [[50 17  3 17 42 17 20 44 35  5  0  0  0  0  0  0  0  0  0  0]]\n",
      "decoder input [[ 1 53  9  8 63 25 68  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "decoder output [[53  9  8 63 25 68  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "decoder output (one-hot) [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Encoder Input\n",
    "training_encoder_input = encoded_training_input\n",
    "\n",
    "# Decoder Input (need padding py START_CHAR_CODE)\n",
    "training_decoder_input = np.zeros_like(encoded_training_output)\n",
    "training_decoder_input[:, 1:] = encoded_training_output[:,:-1]\n",
    "training_decoder_input[:, 0] = START_CHAR_CODE\n",
    "\n",
    "# Decoder Output (one-hot encode)\n",
    "training_decoder_output = np.eye(output_dict_size)[encoded_training_output.astype('int')]\n",
    "\n",
    "\n",
    "print('encoder input', training_encoder_input[:1])\n",
    "print('decoder input', training_decoder_input[:1])\n",
    "print('decoder output', training_decoder_output[:1].argmax(axis=2))\n",
    "print('decoder output (one-hot)', training_decoder_output[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_encoder_input = encoded_validation_input\n",
    "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
    "validation_decoder_input[:, 1:] = encoded_validation_output[:,:-1]\n",
    "validation_decoder_input[:, 0] = START_CHAR_CODE\n",
    "validation_decoder_output = np.eye(output_dict_size)[encoded_validation_output.astype('int')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('model.h5'):\n",
    "    model = load_model('model.h5')\n",
    "else:\n",
    "    model.fit(x=[training_encoder_input, training_decoder_input], y=[training_decoder_output],\n",
    "          validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "          verbose=2, \n",
    "          batch_size=64,\n",
    "          epochs=20)\n",
    "    \n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "During the testing or after deploy the model, to generate the output we will use \"greedy\" generating approach, which is generating one output at a time by maximize softmax score and feed the output back as the next decoder input character. \n",
    "\n",
    "We won't use [beam-search decoding](https://www.quora.com/Why-is-beam-search-required-in-sequence-to-sequence-transduction-using-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "    encoder_input = transform(input_encoding, [text.lower()], 20)\n",
    "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = START_CHAR_CODE\n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
    "        decoder_input[:,i] = output[:,i]\n",
    "    return decoder_input[:,1:]\n",
    "\n",
    "def decode(decoding, sequence):\n",
    "    text = ''\n",
    "    for i in sequence:\n",
    "        if i == 0:\n",
    "            break\n",
    "        text += output_decoding[i]\n",
    "    return text\n",
    "\n",
    "def to_katakana(text):\n",
    "    decoder_output = generate(text)\n",
    "    return decode(output_decoding, decoder_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is trained correctly, typical names should be translate correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James ジェームズ\n",
      "John ジョン\n",
      "Robert ロベルト\n",
      "Mary マリー\n",
      "Patricia パトリシア\n",
      "Linda リンダ\n"
     ]
    }
   ],
   "source": [
    "common_american_names = ['James', 'John', 'Robert', 'Mary', 'Patricia', 'Linda']\n",
    "for name in common_american_names:\n",
    "    print(name, to_katakana(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we train the model with mostly people and places names, some English words may not be written correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コンプター\n",
      "タッキ\n"
     ]
    }
   ],
   "source": [
    "print(to_katakana('computer'))\n",
    "print(to_katakana('taxi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
